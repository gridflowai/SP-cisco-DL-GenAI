{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c919af98-b6de-4bb4-b966-8eda319b8904",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "#### Prompt Engg \n",
    "\n",
    "- basic example using `chat completions`\n",
    "- code contains exmaples from 0.28 and later 1.35/1.45 versions of API\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04fa3336-0bc7-4191-9a98-332f878e1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openai==1.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b2eda6-b4c2-4cb4-aa20-b5ba3007cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# openai_api_key = 'sk-proj-0vEkZMpvAaq9EMjtJWqHT3BlbkFJIsyQBwRE0eQExHf4hHSB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8d0efd0-90bd-4c5e-b744-4f935dd2b142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.45.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63262e-ce88-4ac8-ada0-19602cbf10c9",
   "metadata": {},
   "source": [
    "#### models in openAI\n",
    "------------------------------------\n",
    "\n",
    "OpenAI provides a variety of models, each suited for different use cases, ranging from text generation, code generation, to specific tasks like question answering, summarization, and more.\n",
    "\n",
    "| Model Type               | Description                                                                                       | Model ID               | Variants/Use Cases                                           |\n",
    "|--------------------------|---------------------------------------------------------------------------------------------------|------------------------|-------------------------------------------------------------|\n",
    "| **GPT-4 Models**         | The most advanced language model, designed for a wide range of tasks, including text completion and complex reasoning. | `gpt-4`                | Variants: `gpt-4`, `gpt-4-32k` (larger context window)     |\n",
    "| **GPT-3.5 Models**       | A slightly earlier version of the GPT-4 model, used for efficient and high-quality completions across various tasks. | `gpt-3.5-turbo`        |                                                             |\n",
    "| **Codex Models**         | Specialized for code generation tasks, including programming in multiple languages.              | `code-davinci-002`, `code-cushman-001` | Use cases: Autocomplete for code, bug fixes, code explanations. |\n",
    "| **Text-Davinci Models**  | One of the most capable models for text generation, document completion, and more.              | `text-davinci-003`     | Use cases: Writing, summarization, text generation.         |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b7ccb-8fca-400a-ba94-7d8ce8e152e7",
   "metadata": {},
   "source": [
    "\n",
    "##### Key Properties of Models:\n",
    "- **Token Limit**: Defines how much input and output the model can handle in a single request. For example:\n",
    "  - GPT-4 has a context length limit of 8,192 tokens, and `gpt-4-32k` can handle up to 32,768 tokens.\n",
    "- **Training Data**: The models are trained on a mixture of publicly available and licensed datasets but have a knowledge cutoff (e.g., GPT-4 has a cutoff in September 2021).\n",
    "\n",
    "Each model has a balance of capability, efficiency, and cost, and you can select the right one depending on the task you need to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a731be00-e0e8-49d6-bd72-f5dd9757f8f5",
   "metadata": {},
   "source": [
    "#### Endpoints\n",
    "-----------------------------\n",
    "\n",
    "- OpenAI provides several API endpoints that enable developers to interact with their models for various tasks such as `text generation`, `conversation`, `code completion`, `embedding generation`, and more.\n",
    "\n",
    "- Each endpoint serves a different purpose and can be accessed via HTTP requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628accf0-0e22-4dae-ab90-f4df0542d373",
   "metadata": {},
   "source": [
    "#### 1. Text Completion (Legacy) Endpoint (`/v1/completions`)\n",
    "\n",
    "While still technically supported, the Completions endpoint is considered legacy. It directly generates text from a prompt without the conversation history format used in the Chat endpoint.\n",
    "\n",
    "**API Endpoint**:  \n",
    "POST https://api.openai.com/v1/completions\n",
    "\n",
    "**Usage**:  \n",
    "Legacy usage for tasks like document completion, content generation, and summarization.\n",
    "\n",
    "**Key Parameters**:\n",
    "- `model`: Specifies the model (e.g., `text-davinci-003`).\n",
    "- `prompt`: The input text to be completed.\n",
    "- `max_tokens`: The number of tokens to generate.\n",
    "- `temperature`: Controls randomness in the output (higher value = more creative, lower = more deterministic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af57e6ba-14b8-494e-a9ff-52cbce8447db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c996490-2669-4a19-8e64-95c5a389e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for older 0.28 API\n",
    "# Make a request to the Completions Endpoint\n",
    "# response = openai.Completion.create(\n",
    "#   model       = \"gpt-3.5-turbo\",                                # Specify the model you want to use\n",
    "#   prompt      = \"Once upon a time, there was a wise owl that\",  # Input prompt\n",
    "#   max_tokens  = 50,                                             # The maximum number of tokens to generate\n",
    "#   temperature = 0.7,                                            # Controls randomness (0.7 = moderate creativity)\n",
    "#   n           = 1,                                              # The number of completions to generate\n",
    "#   stop        = None                                            # Optional stop sequence\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe60096-70f8-488d-85c8-002bbcc98da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the generated completion\n",
    "# print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af8e3b8c-42d2-4d8b-b77e-6ab234007007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "#     messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "#     response = openai.ChatCompletion.create(                            # older 0.28 \n",
    "#         model      = model,\n",
    "#         messages   = messages,\n",
    "#         temperature= 0, # this is the degree of randomness of the model's output\n",
    "#     )\n",
    "#     return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce0ab08-f90c-42b1-a60c-f85afdace827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"\n",
    "# Translate the following English sentence to French:\n",
    "\n",
    "# 'Hello, world!'\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd0b8e36-2d38-452b-b856-aeb960bf09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = get_completion(prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8674b2ff-71d4-40f0-b1a8-d10b56a5e657",
   "metadata": {},
   "source": [
    "#### 2. Chat Completion Endpoint (/v1/chat/completions)\n",
    "\n",
    "**Purpose**: Designed for GPT models (GPT-3.5, GPT-4) to handle conversation-like inputs, but can be used for tasks similar to text generation.\n",
    "\n",
    "**API Endpoint**: POST https://api.openai.com/v1/chat/completions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee8783-117c-4aba-8063-6f91576a85c6",
   "metadata": {},
   "source": [
    "\n",
    "**Usage**: Itâ€™s the recommended endpoint for most tasks, including text completion, Q&A, summarization, etc., by providing a chat history as input.\n",
    "\n",
    "**Key Parameters**:\n",
    "\n",
    "- **model**: Specifies the model to be used (e.g., gpt-4 or gpt-3.5-turbo).\n",
    "- **messages**: A list of messages, where each message contains:\n",
    "  - **role**: Either \"system\", \"user\", or \"assistant\".\n",
    "  - **content**: The text for the message.\n",
    "- **max_tokens**: Controls how many tokens to generate.\n",
    "- **temperature**: Controls randomness in the output (higher value = more random).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96831133-5f93-42d7-8246-61fbb099bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b05f8a-39f1-47e9-90d7-7f48fb87c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    # api_key = openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb7ca2f-93a8-4845-8d68-afe8c7adcaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request to the Chat Completion Endpoint\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",  # Specify the model\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Can you summarize the key parameters for the Chat Completion Endpoint?\"}\n",
    "    ],\n",
    "    max_tokens=50,\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2138ecf-69d5-4d66-b4de-67d332e6a23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The key parameters for the Chat Completion Endpoint typically include:\n",
      "\n",
      "1. Chat ID: A unique identifier for the chat session.\n",
      "2. Conversation ID: A unique identifier for the conversation within the chat session.\n",
      "3. Completion Status: Indicates whether the\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc1d4b-0fae-4c7e-b338-33be4e8b2709",
   "metadata": {},
   "source": [
    "#### Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852157d2-7909-4d1e-b1a6-eadb6090628b",
   "metadata": {},
   "source": [
    "In OpenAI's API for language models, messages are the fundamental building blocks of prompts. \n",
    "\n",
    "Each message typically consists of two main components: the `role` of the sender and the `content` of the message. \n",
    "\n",
    "| **Role**   | **Description**                                                                                                                                                 | **Example**                                                                                                                  |\n",
    "|------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------|\n",
    "| User       | Represents the end user or the application initiating the conversation. Sends input messages, asking questions or providing information for the model's response. | If a user asks, \"What is machine learning?\", the message is sent with the role of \"user\".                                  |\n",
    "| Assistant  | Represents the AI model's responses to the userâ€™s queries. Generates replies based on the context and content of previous messages, aiming to be helpful and informative. | After the user asks about machine learning, the assistant might respond, \"Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data.\" |\n",
    "| System     | Provides initial instructions or context to the assistant to guide its behavior throughout the interaction. Typically used to set the tone, rules, or constraints of the assistantâ€™s responses. | A system message might state, \"You are a friendly and informative assistant.\"                                              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c5f1906-99de-426c-9db3-e5d3aaad74fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a knowledgeable assistant.'},\n",
       " {'role': 'user', 'content': 'Can you tell me about neural networks?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Neural networks are a series of algorithms that mimic                                     the operations of a human brain to recognize relationships in a set of data.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "  {\"role\": \"system\",    \"content\": \"You are a knowledgeable assistant.\"},\n",
    "  {\"role\": \"user\",      \"content\": \"Can you tell me about neural networks?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Neural networks are a series of algorithms that mimic \\\n",
    "                                    the operations of a human brain to recognize relationships in a set of data.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e28f0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    #api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87864805-639b-4eb8-bf95-47ff7a0f5edf",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e57599d7-417d-4add-9f43-fe4256e8bb96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create (\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts \\\n",
    "                                   with creative flair.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"Compose a poem that explains the concept of recursion in programming, \\\n",
    "                                   in max 50 words\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069c3b56-2dde-4212-96f6-98864608d464",
   "metadata": {
    "tags": []
   },
   "source": [
    "type(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82a6cbb3-a04a-4503-a9a1-af0a509fc7e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AJ36w5eX7Dc3Eelk9XOcFqzUOZTOt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In coding's realm where patterns unfold,                                     Recursion dances, a tale retold.                                     A function calls itself, a loop untied,                                     Dividing tasks in a recursive stride.                                     Like a Russian doll, layers unfurl,                                     Building beauty in a recursive whirl.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729103554, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=56, prompt_tokens=46, total_tokens=102, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0), prompt_tokens_details={'cached_tokens': 0}))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6352ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(response):\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1c7294a-1bdf-470e-84ec-c11f6a00a5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In coding's realm where patterns unfold,                                     Recursion dances, a tale retold.                                     A function calls itself, a loop untied,                                     Dividing tasks in a recursive stride.                                     Like a Russian doll, layers unfurl,                                     Building beauty in a recursive whirl.\n"
     ]
    }
   ],
   "source": [
    "res= show_result(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd50cb-88b9-43ca-bde3-257a71e45f96",
   "metadata": {},
   "source": [
    "#### Deciphering the completion response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10683914-2495-4e1e-9cfd-93fb55d1b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eb24dd4-7313-4886-83bb-51dcfe9e24bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'length',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'Sure! The key parameters for the Chat '\n",
      "                                     'Completion Endpoint typically include:\\n'\n",
      "                                     '\\n'\n",
      "                                     '1. Chat ID: A unique identifier for the '\n",
      "                                     'chat session.\\n'\n",
      "                                     '2. Conversation ID: A unique identifier '\n",
      "                                     'for the conversation within the chat '\n",
      "                                     'session.\\n'\n",
      "                                     '3. Completion Status: Indicates whether '\n",
      "                                     'the',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant'}}],\n",
      " 'created': 1729103541,\n",
      " 'id': 'chatcmpl-AJ36jKYzllhBLDbo4hGkTv9rMhiPz',\n",
      " 'model': 'gpt-3.5-turbo-0125',\n",
      " 'object': 'chat.completion',\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 50,\n",
      "           'completion_tokens_details': {'reasoning_tokens': 0},\n",
      "           'prompt_tokens': 19,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0},\n",
      "           'total_tokens': 69}}\n"
     ]
    }
   ],
   "source": [
    "# Pretty print the response using pprint\n",
    "pprint(response.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb2f896e-0ff6-4a72-ac3d-a53fcc36357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AJ36jKYzllhBLDbo4hGkTv9rMhiPz\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"length\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Sure! The key parameters for the Chat Completion Endpoint typically include:\\n\\n1. Chat ID: A unique identifier for the chat session.\\n2. Conversation ID: A unique identifier for the conversation within the chat session.\\n3. Completion Status: Indicates whether the\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1729103541,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 50,\n",
      "        \"prompt_tokens\": 19,\n",
      "        \"total_tokens\": 69,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"reasoning_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Serialize to JSON and print\n",
    "json_output = json.dumps(response.to_dict(), indent=4)\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf23bc5-fd08-41da-b6ba-287a313b8c4e",
   "metadata": {},
   "source": [
    "#### Attributes of ChatCompletion\n",
    "\n",
    "| Attribute          | Description                                                                                  |\n",
    "|--------------------|----------------------------------------------------------------------------------------------|\n",
    "| **id**             | A unique identifier for the completion request (e.g., `'chatcmpl-ABc5tNfn75ylhDfYoCrEBNlqk6xqO'`). |\n",
    "| **choices**        | A list of `Choice` objects representing the different responses generated by the model. In this case, there is one choice. |\n",
    "| **created**        | A timestamp indicating when the completion was created (e.g., `1727331405`).               |\n",
    "| **model**          | The model used to generate the completion (e.g., `'gpt-3.5-turbo-0125'`).                   |\n",
    "| **object**         | The type of object, which indicates it's a `chat.completion`.                               |\n",
    "| **usage**          | An object that details the token usage for the request and response, including:            |\n",
    "|                    | - **completion_tokens**: Number of tokens used in the completion (e.g., `45`).              |\n",
    "|                    | - **prompt_tokens**: Number of tokens used in the input prompt (e.g., `46`).               |\n",
    "|                    | - **total_tokens**: Total number of tokens used (e.g., `91`).                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535a01d-3e30-4dbc-a92f-f961874d9fb1",
   "metadata": {},
   "source": [
    "**Choices**\n",
    "\n",
    "| Attribute               | Description                                                                                              |\n",
    "|-------------------------|----------------------------------------------------------------------------------------------------------|\n",
    "| **finish_reason**        | The reason the completion finished (e.g., `'stop'`).                                                     |\n",
    "| **index**                | The index of the choice in the list.                                                                     |\n",
    "| **logprobs**             | Any associated log probabilities (in this case, it's `None`).                                            |\n",
    "| **message**              | An instance of `ChatCompletionMessage` that contains:                                                    |\n",
    "| - **content**            | The actual text generated by the model (e.g., a poem about recursion).                                   |\n",
    "| - **role**               | The role of the entity that generated the message (e.g., `'assistant'`).                                 |\n",
    "| - **function_call**      | Information if the message included a function call (in this case, it's `None`).                         |\n",
    "| - **tool_calls**         | Information if there were any tool calls (also `None` in this case).                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d53aa-bda7-41a8-b2c4-073a08bfb7e9",
   "metadata": {},
   "source": [
    "#### Exercise - 01 \n",
    "\n",
    "- (extract pieces of info from the completion response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8115f837-5c37-4f48-a8e9-310bf2564c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020?\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e56469a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Los Angeles Dodgers won the World Series in 2020, defeating the Tampa Bay Rays.\n"
     ]
    }
   ],
   "source": [
    "res = show_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487a118-0324-4dd3-ac2d-6c5438d62b9b",
   "metadata": {},
   "source": [
    "Qs : Extract the model name from the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7914f28-801f-4943-aa4e-9f8b9f631f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used: gpt-3.5-turbo-0125\n"
     ]
    }
   ],
   "source": [
    "# Expected solution\n",
    "model_name = response.to_dict()['model']\n",
    "print(\"Model used:\", model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80127c-8fe5-40c4-850f-18f413a9354a",
   "metadata": {},
   "source": [
    "Qs : Extract the content of the assistantâ€™s reply from the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "574aaefb-86ba-4633-a003-5f9f13d60edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant's reply: The Los Angeles Dodgers won the World Series in 2020, defeating the Tampa Bay Rays.\n"
     ]
    }
   ],
   "source": [
    "# Expected solution\n",
    "assistant_reply = response.to_dict()['choices'][0]['message']['content']\n",
    "print(\"Assistant's reply:\", assistant_reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878d128-3be9-49da-b4fe-8a9f9df468b7",
   "metadata": {},
   "source": [
    "let us change the prompt to add a few more years ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dad810e6-a552-4fcf-9556-b7e5d4a8b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020, 2021, 2022, 2023 ?\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdef999-fd70-441d-b5c1-ee04053c2991",
   "metadata": {},
   "source": [
    "Qs : Create a dictionary of World Series winners by year from the assistantâ€™s reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "846e697b-5095-4839-ac63-64f9f88ad458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winners of the World Series from 2020 to 2023 are as follows:\n",
      "\n",
      "- **2020**: Los Angeles Dodgers\n",
      "- **2021**: Atlanta Braves\n",
      "- **2022**: Houston Astros\n",
      "- **2023**: Texas Rangers\n",
      "\n",
      "If you need more information about any of these series, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Example solution\n",
    "winners_by_year = response.to_dict()['choices'][0]['message']['content']\n",
    "print(winners_by_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ad129-984b-4820-b3c8-8e0b04de58cb",
   "metadata": {},
   "source": [
    "Get the output in a dictionary format, year : winner name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e5d092d-9024-4978-a9ab-c82762b63e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020, 2021, 2022, 2023 ? \\\n",
    "                                       Provide the answer in a dictionary format as below \\\n",
    "                                       year : winner name \\\n",
    "                                       \"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48ced7f3-3fd7-4486-9e2b-b0665cfcb9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the information you requested in a dictionary format:\n",
      "\n",
      "```python\n",
      "{\n",
      "    2020: \"Los Angeles Dodgers\",\n",
      "    2021: \"Atlanta Braves\",\n",
      "    2022: \"Houston Astros\",\n",
      "    2023: \"Texas Rangers\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Example solution\n",
    "winners_by_year = response.to_dict()['choices'][0]['message']['content']\n",
    "print(winners_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd8abe32-6233-44b9-a801-c5c56cb23057",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": '''Who won the world series in 2020, 2021, 2022, 2023 ? \\\n",
    "                                       Provide the answer in a dictionary format as below \\\n",
    "                                       {\n",
    "                                           year : winner name \n",
    "                                       }\n",
    "                                       without any extra text\n",
    "                                       \\\n",
    "                                       '''},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40480a65-9e0e-4637-88ef-d5f027a22905",
   "metadata": {},
   "source": [
    "Qs : load the output in dataframe format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4198a5-7306-4538-8390-157feec00776",
   "metadata": {},
   "source": [
    "| Year | Winner                |\n",
    "|------|-----------------------|\n",
    "| 2020 | Los Angeles Dodgers   |\n",
    "| 2021 | Atlanta Braves        |\n",
    "| 2022 | Houston Astros        |\n",
    "| 2023 | Texas Rangers         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7e0e956-923d-4e45-a9b4-4b74cca07ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  2020: \"Los Angeles Dodgers\",\\n  2021: \"Atlanta Braves\",\\n  2022: \"Houston Astros\",\\n  2023: \"Texas Rangers\"\\n}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example solution\n",
    "winners_by_year = response.to_dict()['choices'][0]['message']['content']\n",
    "winners_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e88ae9b-8197-49a5-b58e-fc66db1c00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a7e788b-abc3-4a04-b23f-a987ed0945fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string representation of the dictionary to an actual dictionary\n",
    "world_series_dict = ast.literal_eval(winners_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e0ff90d-376e-4e7a-b481-8e2326fe85ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>Atlanta Braves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>Houston Astros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Texas Rangers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year               Winner\n",
       "0  2020  Los Angeles Dodgers\n",
       "1  2021       Atlanta Braves\n",
       "2  2022       Houston Astros\n",
       "3  2023        Texas Rangers"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dictionary into a pandas DataFrame\n",
    "df = pd.DataFrame(list(world_series_dict.items()), columns=['Year', 'Winner'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6ffca6-b8a5-4bf6-a3db-a41a93a0dfc2",
   "metadata": {},
   "source": [
    "Qs : Extract only the winner names from the dictionary and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59612042-e735-4211-a194-79f20257114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary\n",
    "world_series_dict = ast.literal_eval(winners_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bca9df0c-594f-4939-8be9-127b6bcd06d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Los Angeles Dodgers', 'Atlanta Braves', 'Houston Astros', 'Texas Rangers']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract winners\n",
    "winners = list(world_series_dict.values())\n",
    "winners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df9865-7874-4ff4-9ad9-cb03bf27adc7",
   "metadata": {},
   "source": [
    "Qs : Convert the dictionary into a list of tuples with (Year, Winner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e03cb45-ef5b-4b54-afa3-65bf060ecb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary\n",
    "world_series_dict = ast.literal_eval(winners_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99763f2a-0a7d-47bf-982a-182224d4d1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2020, 'Los Angeles Dodgers'),\n",
       " (2021, 'Atlanta Braves'),\n",
       " (2022, 'Houston Astros'),\n",
       " (2023, 'Texas Rangers')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to list of tuples\n",
    "year_winner_tuples = list(world_series_dict.items())\n",
    "year_winner_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae940973-833c-4fa3-99bd-72a4ae2c0ea9",
   "metadata": {},
   "source": [
    "Qs : Write a function that checks if a given team won the World Series in a specified year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "556c6b28-d569-4da2-9840-54412c7eecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def did_team_win(year, team):\n",
    "    return world_series_dict.get(year) == team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61889072-da5f-42a1-aa2b-f591a6442a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "print(did_team_win(2020, \"Los Angeles Dodgers\"))  # Expected: True\n",
    "print(did_team_win(2021, \"Los Angeles Dodgers\"))  # Expected: False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e24da-bb76-4c9b-b189-7b31a105ea9e",
   "metadata": {},
   "source": [
    "Qs : Find the most recent World Series winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2236aa6b-214d-473f-aa8e-72ecc554e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent year\n",
    "most_recent_year = max(world_series_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23e1a5ea-826a-4df9-aca7-64ad502e89dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent winner is Texas Rangers in 2023.\n"
     ]
    }
   ],
   "source": [
    "# Get the winner of the most recent year\n",
    "most_recent_winner = world_series_dict[most_recent_year]\n",
    "\n",
    "# Print the most recent winner\n",
    "print(f\"The most recent winner is {most_recent_winner} in {most_recent_year}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5025f-8f2b-4db0-b2c1-2554914b9336",
   "metadata": {},
   "source": [
    "#### Finish Reason Summary\n",
    "\n",
    "| Finish Reason      | Description                                                                                                            | Example                             |\n",
    "|--------------------|------------------------------------------------------------------------------------------------------------------------|-------------------------------------|\n",
    "| \"stop\"             | The model completed its response naturally, reaching a logical stopping point like the end of a sentence or thought.  | \"finish_reason\": \"stop\"            |\n",
    "| \"length\"           | The response was cut off because the model reached the maximum number of tokens allowed in the API request.            | \"finish_reason\": \"length\"          |\n",
    "| \"content_filter\"   | The response was stopped because it triggered the safety filter, likely due to generating inappropriate or unsafe content. | \"finish_reason\": \"content_filter\"  |\n",
    "| null               | The completion ended for an unknown or unspecified reason, or there was no particular reason captured (rare, edge case scenario). | \"finish_reason\": null               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b8c36-4f1c-4868-9197-590a16e80b09",
   "metadata": {},
   "source": [
    "#### Index Attribute Summary\n",
    "\n",
    "| Index | Description                                                                                      | Example                 |\n",
    "|-------|--------------------------------------------------------------------------------------------------|-------------------------|\n",
    "| 0     | The index of the choice in the list of choices returned by the model. It typically starts at 0. | \"index\": 0              |\n",
    "| 1     | Indicates the second choice in the list, if multiple choices are generated.                      | \"index\": 1              |\n",
    "| 2     | Represents the third choice in the list of generated responses, if applicable.                   | \"index\": 2              |\n",
    "| ...   | Continues incrementing for additional choices returned, based on the number of choices.         | \"index\": n (where n is the choice number) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d823cb6-c4a8-4587-9de7-92af2485c2c7",
   "metadata": {},
   "source": [
    "#### Message Attribute Summary\n",
    "\n",
    "| Attribute         | Description                                                                                             | Example                                                              |\n",
    "|-------------------|---------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------|\n",
    "| content           | The actual text generated by the model, representing the response.                                     | \"content\": \"This is the generated text.\"                            |\n",
    "| role              | Indicates the role of the entity that generated the message, typically \"assistant\" for model responses.| \"role\": \"assistant\"                                                 |\n",
    "| function_call     | Contains information about any function calls included in the message, if applicable (otherwise None).| \"function_call\": None                                               |\n",
    "| tool_calls        | Provides information about any tool calls made during the response generation (usually None).          | \"tool_calls\": None                                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161c470-e960-470e-9211-d599df653dcb",
   "metadata": {},
   "source": [
    "#### Reasoning abilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a0c16e9-b1e4-484b-9c30-cb3a344cc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''\n",
    "during the start of the training program, the learners were asked if they wished certain AI topics or lessons\n",
    "they would like the instructor to provide a quick recap or brush up and illustrations. Based of their feedback\n",
    "the instructor captured list of topics for the recap. The agreed assumption was that the learners are familiar with\n",
    "the topics but needed a quick refresher on them. The instructor provided walk thru on each of the topics with examples and illustration \n",
    "with python codes and gave them time of 5 mins on each topic if they had any qs or difficulties. During the entire 4 sessions the learners\n",
    "do not complaing about understanding the concepts, code, examples even after being polled explicitly for their repsonse.\n",
    "But a couple of them provide feedback at the end of the week to their manager, instead. leaving the instructor completely unaware.\n",
    "'''\n",
    "\n",
    "feedback = '''\n",
    "the trainerâ€™s pace was slower than expected, and it seemed like he was copying code from his notebook \n",
    "without providing sufficient explanations on the \"what\" and \"why\" behind the actions. \n",
    "need for more in-depth explanations and context.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54c6b166-c5eb-4c5b-8ec0-a000369f0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant with abilities to interpret learners' feedback.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Based on the {context}, assess if there are contradictions in the {feedback}. \\\n",
    "        Provide a clear explanation of your understanding of the feedback \\\n",
    "        Provide areas where learners could have helped the trainer in the recap sessions\"}\n",
    "    ],\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "684a4c44-9d21-41e9-9d5e-11c9e743f1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the feedback provided, there are several contradictions and areas for improvement that can be identified:\n",
      "\n",
      "### Understanding of the Feedback\n",
      "\n",
      "1. **Learner Familiarity vs. Need for Depth**: The initial assumption was that learners were familiar with the topics and only needed a quick refresher. However, the feedback indicates that learners felt the pace was slower than expected and that the instructor was merely copying code without sufficient explanations. This suggests that while learners may have had some familiarity, they were still seeking deeper understanding and context for the material being presented.\n",
      "\n",
      "2. **Lack of Communication**: The fact that learners did not express their concerns during the sessions but instead provided feedback to their manager indicates a communication gap. The instructor was unaware of the learners' dissatisfaction, which could have been addressed in real-time if learners had felt comfortable voicing their concerns.\n",
      "\n",
      "3. **Need for In-Depth Explanations**: The feedback highlights a desire for more in-depth explanations regarding the \"what\" and \"why\" of the code and concepts being discussed. This suggests that learners were looking for a more comprehensive understanding rather than just a surface-level overview.\n",
      "\n",
      "### Areas Where Learners Could Have Helped the Trainer\n",
      "\n",
      "1. **Active Participation**: Learners could have been more proactive in asking questions during the recap sessions. If they felt that the explanations were insufficient, they should have voiced their concerns or asked for clarification on specific points.\n",
      "\n",
      "2. **Providing Feedback During Sessions**: Instead of waiting until the end of the week to provide feedback to their manager, learners could have given immediate feedback to the instructor. This would have allowed the instructor to adjust the pace and depth of the material in real-time.\n",
      "\n",
      "3. **Clarifying Expectations**: Learners could have communicated their expectations more clearly at the beginning of the training. If they were looking for more in-depth explanations, they could have specified this during the initial feedback session.\n",
      "\n",
      "4. **Engagement in Discussions**: Encouraging a more interactive environment where learners could share their thoughts and experiences related to the topics could have helped the instructor gauge their understanding and adjust the content accordingly.\n",
      "\n",
      "5. **Feedback Mechanisms**: Implementing a more structured feedback mechanism during the sessions, such as quick polls or feedback forms, could have provided the instructor with insights into the learners' understanding and satisfaction levels.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "In summary, while the instructor aimed to provide a recap based on the assumption of learner familiarity, the feedback indicates a need for deeper engagement and understanding. Learners could have played a more active role in communicating their needs and expectations, which would have facilitated a more effective learning experience.\n"
     ]
    }
   ],
   "source": [
    "print(response.to_dict()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80105fbf-174d-4daf-b0ae-916cf513d11c",
   "metadata": {},
   "source": [
    "\n",
    "## Useful applications of messaging structure\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e46e723-9d3e-42fe-af2f-258faf5653bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the conversation with a system message\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0cd7127-7426-4c85-8d50-2812cb2f415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(conversation):\n",
    "    # Send the conversation to the OpenAI API and get a response\n",
    "    response = client.chat.completions.create(\n",
    "        model    = \"gpt-3.5-turbo\",\n",
    "        messages = conversation\n",
    "    )\n",
    "    return response.to_dict()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17c3bb66-881a-41ea-970e-7d6651cd1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user messages incrementally\n",
    "user_inputs = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Can you tell me more about its culture?\",\n",
    "    \"What are some famous landmarks there?\",\n",
    "    \"How is the cuisine different from other countries?\",\n",
    "    \"What is the best time of year to visit?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d86ce52a-0ba7-493e-9421-0300e2d6bf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the capital of France?\n",
      "Assistant: The capital of France is Paris.\n",
      "--------------------------------------------------\n",
      "User: Can you tell me more about its culture?\n",
      "Assistant: Certainly! France has a rich and diverse culture that has made significant contributions to art, literature, music, cuisine, fashion, and more. French cuisine is renowned worldwide for its delicious food and wine. The country also has a long history of artistic achievement, with famous painters like Claude Monet and Auguste Renoir, as well as writers such as Victor Hugo and Albert Camus.\n",
      "\n",
      "French fashion is known for its elegance and sophistication, with Paris being regarded as one of the fashion capitals of the world. In terms of music, France has produced iconic musicians and composers like Edith Piaf, Claude Debussy, and Maurice Ravel.\n",
      "\n",
      "French culture also places a high value on intellectual pursuits, with a strong tradition of philosophy and critical thinking. Overall, France's culture is a blend of historical traditions and contemporary influences that make it a vibrant and dynamic place to explore.\n",
      "--------------------------------------------------\n",
      "User: What are some famous landmarks there?\n",
      "Assistant: France is home to many iconic landmarks that attract millions of visitors each year. Some of the most famous landmarks in France include:\n",
      "\n",
      "1. Eiffel Tower - Located in Paris, the Eiffel Tower is perhaps the most famous symbol of France. It offers stunning views of the city from its observation decks.\n",
      "\n",
      "2. Louvre Museum - Also in Paris, the Louvre is one of the largest and most famous art museums in the world, housing masterpieces like the Mona Lisa and the Venus de Milo.\n",
      "\n",
      "3. Palace of Versailles - This opulent palace, located near Paris, was the former royal residence of French kings. Its grand architecture and exquisite gardens make it a must-visit destination.\n",
      "\n",
      "4. Mont Saint-Michel - A medieval abbey perched on a rocky island in Normandy, Mont Saint-Michel is a UNESCO World Heritage site and a breathtaking example of Gothic architecture.\n",
      "\n",
      "5. Notre-Dame Cathedral - Another iconic Paris landmark, Notre-Dame is a stunning example of French Gothic architecture and is known for its intricate sculptures and stained glass windows.\n",
      "\n",
      "These are just a few of the many famous landmarks in France that showcase the country's rich history and cultural heritage.\n",
      "--------------------------------------------------\n",
      "User: How is the cuisine different from other countries?\n",
      "Assistant: French cuisine is highly regarded around the world for its sophistication, diversity, and emphasis on quality ingredients and culinary techniques. Some key aspects that set French cuisine apart from others include:\n",
      "\n",
      "1. Emphasis on fresh, high-quality ingredients: French cuisine prioritizes the use of fresh, seasonal ingredients sourced locally. The focus is on using the best-quality produce, meats, and seafood to create delicious dishes.\n",
      "\n",
      "2. Culinary techniques: French cuisine is known for its intricate and refined culinary techniques, such as sautÃ©ing, braising, roasting, and baking. French chefs are highly skilled in these techniques, which allow them to elevate simple ingredients into gourmet dishes.\n",
      "\n",
      "3. Sauces and aromatics: French cuisine is famous for its rich and flavorful sauces, which are often made from scratch using ingredients like wine, stock, herbs, and aromatic vegetables. These sauces add depth and complexity to dishes.\n",
      "\n",
      "4. Art of pastry and baking: French patisserie is renowned for its delicate pastries, tarts, and cakes. French bakers are masters at creating flaky croissants, buttery macarons, and decadent desserts that showcase precision and creativity.\n",
      "\n",
      "5. Food culture and dining experience: In France, dining is considered an art form, and meals are often enjoyed leisurely with good company. The French take time to savor and appreciate their food, making dining a social and cultural experience.\n",
      "\n",
      "Overall, French cuisine's attention to detail, quality ingredients, and culinary traditions set it apart and have established it as one of the most influential and admired cuisines in the world.\n",
      "--------------------------------------------------\n",
      "User: What is the best time of year to visit?\n",
      "Assistant: The best time of year to visit France can depend on your preferences and the activities you want to enjoy. Here are some considerations for each season:\n",
      "\n",
      "1. Spring (March to May): Spring is a popular time to visit France, as the weather is mild, and the landscape comes alive with blooming flowers and greenery. This is a great time for outdoor activities, exploring gardens, and experiencing local festivals.\n",
      "\n",
      "2. Summer (June to August): Summer is peak tourist season in France, especially in popular destinations like Paris and the French Riviera. The weather is warm and ideal for outdoor dining, beach activities, and exploring historical sites. Keep in mind that some areas can be crowded during this time.\n",
      "\n",
      "3. Fall (September to November): Fall is a wonderful time to visit France, as the weather is still pleasant, and the crowds start to thin out. The changing foliage in regions like Provence and Normandy can be particularly beautiful. Fall is also harvest season, so it's a great time to enjoy wine tasting and local produce.\n",
      "\n",
      "4. Winter (December to February): Winter in France can be cold, especially in the northern regions, but it can also be a magical time to visit. Paris is beautifully decorated for the holidays, and you can enjoy festive markets and events. The French Alps are perfect for winter sports enthusiasts, with skiing and snowboarding opportunities.\n",
      "\n",
      "Ultimately, the best time to visit France depends on your personal preferences and the experiences you are seeking. Whether you prefer mild weather for sightseeing, outdoor activities, or winter sports, France offers something for every season.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Iterate through user inputs\n",
    "for user_input in user_inputs:\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # Get assistant's response\n",
    "    assistant_response = send_message(conversation)\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    \n",
    "    # Print the latest response\n",
    "    print(\"User:\", user_input)\n",
    "    print(\"Assistant:\", assistant_response)\n",
    "    print(\"-\" * 50)  # Separator for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c3cdc5b-3068-45e2-a2d6-d240fb877ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'What is the capital of France?'},\n",
       " {'role': 'assistant', 'content': 'The capital of France is Paris.'},\n",
       " {'role': 'user', 'content': 'Can you tell me more about its culture?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Certainly! France has a rich and diverse culture that has made significant contributions to art, literature, music, cuisine, fashion, and more. French cuisine is renowned worldwide for its delicious food and wine. The country also has a long history of artistic achievement, with famous painters like Claude Monet and Auguste Renoir, as well as writers such as Victor Hugo and Albert Camus.\\n\\nFrench fashion is known for its elegance and sophistication, with Paris being regarded as one of the fashion capitals of the world. In terms of music, France has produced iconic musicians and composers like Edith Piaf, Claude Debussy, and Maurice Ravel.\\n\\nFrench culture also places a high value on intellectual pursuits, with a strong tradition of philosophy and critical thinking. Overall, France's culture is a blend of historical traditions and contemporary influences that make it a vibrant and dynamic place to explore.\"},\n",
       " {'role': 'user', 'content': 'What are some famous landmarks there?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"France is home to many iconic landmarks that attract millions of visitors each year. Some of the most famous landmarks in France include:\\n\\n1. Eiffel Tower - Located in Paris, the Eiffel Tower is perhaps the most famous symbol of France. It offers stunning views of the city from its observation decks.\\n\\n2. Louvre Museum - Also in Paris, the Louvre is one of the largest and most famous art museums in the world, housing masterpieces like the Mona Lisa and the Venus de Milo.\\n\\n3. Palace of Versailles - This opulent palace, located near Paris, was the former royal residence of French kings. Its grand architecture and exquisite gardens make it a must-visit destination.\\n\\n4. Mont Saint-Michel - A medieval abbey perched on a rocky island in Normandy, Mont Saint-Michel is a UNESCO World Heritage site and a breathtaking example of Gothic architecture.\\n\\n5. Notre-Dame Cathedral - Another iconic Paris landmark, Notre-Dame is a stunning example of French Gothic architecture and is known for its intricate sculptures and stained glass windows.\\n\\nThese are just a few of the many famous landmarks in France that showcase the country's rich history and cultural heritage.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'How is the cuisine different from other countries?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"French cuisine is highly regarded around the world for its sophistication, diversity, and emphasis on quality ingredients and culinary techniques. Some key aspects that set French cuisine apart from others include:\\n\\n1. Emphasis on fresh, high-quality ingredients: French cuisine prioritizes the use of fresh, seasonal ingredients sourced locally. The focus is on using the best-quality produce, meats, and seafood to create delicious dishes.\\n\\n2. Culinary techniques: French cuisine is known for its intricate and refined culinary techniques, such as sautÃ©ing, braising, roasting, and baking. French chefs are highly skilled in these techniques, which allow them to elevate simple ingredients into gourmet dishes.\\n\\n3. Sauces and aromatics: French cuisine is famous for its rich and flavorful sauces, which are often made from scratch using ingredients like wine, stock, herbs, and aromatic vegetables. These sauces add depth and complexity to dishes.\\n\\n4. Art of pastry and baking: French patisserie is renowned for its delicate pastries, tarts, and cakes. French bakers are masters at creating flaky croissants, buttery macarons, and decadent desserts that showcase precision and creativity.\\n\\n5. Food culture and dining experience: In France, dining is considered an art form, and meals are often enjoyed leisurely with good company. The French take time to savor and appreciate their food, making dining a social and cultural experience.\\n\\nOverall, French cuisine's attention to detail, quality ingredients, and culinary traditions set it apart and have established it as one of the most influential and admired cuisines in the world.\"},\n",
       " {'role': 'user', 'content': 'What is the best time of year to visit?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"The best time of year to visit France can depend on your preferences and the activities you want to enjoy. Here are some considerations for each season:\\n\\n1. Spring (March to May): Spring is a popular time to visit France, as the weather is mild, and the landscape comes alive with blooming flowers and greenery. This is a great time for outdoor activities, exploring gardens, and experiencing local festivals.\\n\\n2. Summer (June to August): Summer is peak tourist season in France, especially in popular destinations like Paris and the French Riviera. The weather is warm and ideal for outdoor dining, beach activities, and exploring historical sites. Keep in mind that some areas can be crowded during this time.\\n\\n3. Fall (September to November): Fall is a wonderful time to visit France, as the weather is still pleasant, and the crowds start to thin out. The changing foliage in regions like Provence and Normandy can be particularly beautiful. Fall is also harvest season, so it's a great time to enjoy wine tasting and local produce.\\n\\n4. Winter (December to February): Winter in France can be cold, especially in the northern regions, but it can also be a magical time to visit. Paris is beautifully decorated for the holidays, and you can enjoy festive markets and events. The French Alps are perfect for winter sports enthusiasts, with skiing and snowboarding opportunities.\\n\\nUltimately, the best time to visit France depends on your personal preferences and the experiences you are seeking. Whether you prefer mild weather for sightseeing, outdoor activities, or winter sports, France offers something for every season.\"}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19d78313-cf40-4e13-9ef1-8bb151a83d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553aa06-a9d3-41a0-938e-41ca506040c1",
   "metadata": {},
   "source": [
    "**Strategies to Manage Conversation Length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d06231-3a7b-4c8d-b2d6-4150fbf9d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the conversation with a system message\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a682b-cfd6-4618-b5c9-3f684baa8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(conversation):\n",
    "    # Send the conversation to the OpenAI API and get a response\n",
    "    response = client.chat.completions.create(\n",
    "        model    = \"gpt-3.5-turbo\",\n",
    "        messages = conversation\n",
    "    )\n",
    "    return response.to_dict()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90a43f-96ea-4a52-9c11-ccc595cceecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user messages incrementally\n",
    "user_inputs = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Can you tell me more about its culture?\",\n",
    "    \"What are some famous landmarks there?\",\n",
    "    \"How is the cuisine different from other countries?\",\n",
    "    \"What is the best time of year to visit?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf629ad7-ea13-4c1b-b58c-debfc9308afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a limit for how many exchanges to keep\n",
    "max_history_length = 6  # Total messages to keep (including system message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd6d8a7-d8ba-4d13-8b16-eb8d4c6071e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to indicate if the initial question has been answered\n",
    "initial_question_responded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505cf6b0-732c-4c48-8a72-b3970ed5ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through user inputs\n",
    "for user_input in user_inputs:\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # Get assistant's response\n",
    "    assistant_response = send_message(conversation)\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    \n",
    "    # Print the latest response\n",
    "    print(\"User:\", user_input)\n",
    "    print(\"Assistant:\", assistant_response)\n",
    "    print(\"-\" * 50)  # Separator for clarity\n",
    "\n",
    "    # Truncate the conversation to the most recent exchanges\n",
    "    if len(conversation) > max_history_length:\n",
    "        # Always keep the first question and its response\n",
    "        if not initial_question_responded:\n",
    "            # Keep the first user question and its response\n",
    "            initial_question = conversation[1]  # User question\n",
    "            initial_response = conversation[2]  # Assistant response\n",
    "            # Retain them in the conversation\n",
    "            conversation = [conversation[0], initial_question, initial_response]\n",
    "            initial_question_responded = True\n",
    "        else:\n",
    "            # Keep only the last `max_history_length` messages\n",
    "            conversation = conversation[-max_history_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3baab-742c-4f37-a313-b0aae3a70035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final conversation for verification\n",
    "print(\"\\nFinal conversation:\")\n",
    "for message in conversation:\n",
    "    print(f\"{message['role'].capitalize()}: {message['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8d7e6-1de0-4edb-b288-11aab601f2a8",
   "metadata": {},
   "source": [
    "## Other NLP applications with the LLM\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b823ce-d8e2-4cfd-af8c-9e4fbf9d32ff",
   "metadata": {},
   "source": [
    "#### Language Translation\n",
    "The OpenAI API also supports language translation. \n",
    "\n",
    "You can provide a piece of text in one language and ask the API to translate it into another language. Hereâ€™s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b040ef3b-20c8-43d8-8ba7-7308f6426bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3af22a8-e594-4618-a448-babb2ad50a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create (\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"Compose a poem that explains the \\\n",
    "                                   concept of recursion in programming, \\\n",
    "                                   in max 50 words\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3bd5aafc-6dc3-4752-b48f-56c8ad8bc59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text = \"Hello, how are you?\"\n",
    "\n",
    "# response = openai.Completion.create(\n",
    "#   engine = \"text-davinci-003\",\n",
    "#   prompt = f\"Translate from English to Hindi: {text}\",\n",
    "#   max_tokens=50\n",
    "# )\n",
    "\n",
    "# translation = response.choices[0].text.strip()\n",
    "# print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97256db8-6984-4864-9be0-ddcf14a28e54",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis\n",
    "You can also use the OpenAI API for sentiment analysis. Given a piece of text, the API will tell you whether it has a positive or negative sentiment. Hereâ€™s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2d9bfbb-d028-4688-b4ea-923a7df3d1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the text \"I love horror movies!\" is positive. The use of the word \"love\" indicates a strong positive sentiment towards horror movies.\n"
     ]
    }
   ],
   "source": [
    "text = \"I love horror movies!\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "                  model=\"gpt-3.5-turbo\",\n",
    "                  messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a NLP expert\"},\n",
    "                    {\"role\": \"user\",   \"content\": f\"Perform sentiment analysis of given text : {text}\"\n",
    "                    \n",
    "                    }\n",
    "                  ]\n",
    ")\n",
    "\n",
    "sentiment = response.choices[0].message.content.replace(\"\\n\", \" \")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebcdef2-ea53-4c66-a15c-8cfa1ecddd33",
   "metadata": {},
   "source": [
    "#### Question-Answering\n",
    "The OpenAI API also supports question-answering. You can provide a context and a question, and the API will return an answer based on that context. Hereâ€™s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f93c07fd-baaf-45f7-96b6-b69d32670da7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein was born in Ulm, in the Kingdom of WÃ¼rttemberg in the German Empire on March 14, 1879.\n"
     ]
    }
   ],
   "source": [
    "context  = \"Albert Einstein was a German-born theoretical physicist who developed the \\\n",
    "theory of relativity.\"\n",
    "\n",
    "question = \"Where was Albert Einstein born?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "                  model=\"gpt-3.5-turbo\",\n",
    "                  messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a NLP expert\"},\n",
    "                    {\"role\": \"user\",   \"content\": f\"Question answering:\\nContext: {context}\\nQuestion: {question}\"\n",
    "                    \n",
    "                    }\n",
    "                  ],\n",
    "                 temperature= 0.001\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content.replace(\"\\n\", \" \")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "14c3366d-f26d-401b-8f62-03e2bc9c1429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Yes  Explanation: The patient underwent radiation therapy concurrently with chemotherapy for the paraspinal mass, followed by systemic therapy with carboplatin and pemetrexed. This indicates recent past treatment involving radiation therapy.  Confidence Score/label: 90%\n"
     ]
    }
   ],
   "source": [
    "context = '''positive for TTF 1, and napsin A, \n",
    "suggestive of lung adenocarcinoma. Molecular testing was performed, that did not reveal actionable\n",
    "therapeutically targetable mutations. She underwent chemotherapy and radiation therapy, \n",
    "to this paraspinal mass, administered concurrently with carboplatin and paclitaxel. \n",
    "She was then treated with 4 cycles of systemic therapy with carboplatin, and pemetrexed, and then.'''\n",
    "\n",
    "question = '''\n",
    "\n",
    "Did the patient undergo radiation therapy or any similar therapies in recent past or in the past? \n",
    "\n",
    "Your answer should be either 'Yes' or 'NO' or \"Not sure' ONLY, With a label prefix \"Answer\",\n",
    "Followed by reasoning in 50 words with a label prefix \"Explanation\",\n",
    "followed by confidence score & scale, with a label prefix \"Confidence Score/ label : \"\n",
    "\n",
    "'''\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "                  model=\"gpt-3.5-turbo\",\n",
    "                  messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a NLP expert\"},\n",
    "                    {\"role\": \"user\",   \"content\": f\"Question answering:\\nContext: {context}\\nQuestion: {question}\",\n",
    "                    \n",
    "                    }\n",
    "                  ],\n",
    "                 temperature= 0.001\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content.replace(\"\\n\", \" \")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fbc7e-c859-428d-bfa5-238cabfacdca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
